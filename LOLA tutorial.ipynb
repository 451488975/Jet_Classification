{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOLA tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper link:https://arxiv.org/pdf/1707.08966.pdf\n",
    "Read the paper before doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Understanding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link:https://zenodo.org/record/2603256#.X7VrlGhKiUm\n",
    "There are 3 files, contains in total 1.2M training events, 400k validation events and 400k test events. We will work with training dataset, whichi is the 1GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "input_filename = \"train.h5\"\n",
    "store = pandas.read_hdf(input_filename,'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             E_0        PX_0        PY_0        PZ_0         E_1        PX_1  \\\n",
       "375  474.071136 -250.347031 -223.651962 -334.738098  103.236237  -48.866222   \n",
       "377  150.504532  120.062393   76.852005  -48.274265   82.257057   63.801739   \n",
       "378  251.645386   10.427651 -147.573746  203.564880  104.147797   10.718256   \n",
       "379  451.566132  129.885437  -99.066292 -420.984100  208.410919   59.033958   \n",
       "380  399.093903 -168.432083  -47.205597 -358.717438  273.691956 -121.926941   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "587  206.171997   13.942102  114.328499 -171.001465  231.602356   19.010832   \n",
       "591  263.984161  -40.649391 -104.321312  239.065552  238.690689    8.786323   \n",
       "592   61.417538   42.901291   43.947723   -0.436818   45.521763   31.723654   \n",
       "593  261.215302   12.780115 -132.699203  224.635300  224.066376   52.028233   \n",
       "596  221.000015  -32.458290 -127.960335 -177.238876  109.126007  -16.046606   \n",
       "\n",
       "           PY_1        PZ_1         E_2       PX_2  ...  E_199  PX_199  \\\n",
       "375  -56.790775  -71.025490  105.255569 -55.415001  ...    0.0     0.0   \n",
       "377   42.754807  -29.454842   48.573559  36.763199  ...    0.0     0.0   \n",
       "378  -54.497948   88.101395   78.043213   5.724113  ...    0.0     0.0   \n",
       "379  -46.177090 -194.467941  190.183304  54.069675  ...    0.0     0.0   \n",
       "380  -30.803854 -243.088928  152.837219 -44.400204  ...    0.0     0.0   \n",
       "..          ...         ...         ...        ...  ...    ...     ...   \n",
       "587   92.303848 -211.561432   95.868248   0.411594  ...    0.0     0.0   \n",
       "591 -101.236137  215.979828  126.197868   5.939164  ...    0.0     0.0   \n",
       "592   32.643845   -0.469300   44.801167  29.730831  ...    0.0     0.0   \n",
       "593 -101.145271  193.050354   67.573616  17.166769  ...    0.0     0.0   \n",
       "596  -62.676899  -87.878311  111.210052   0.395372  ...    0.0     0.0   \n",
       "\n",
       "     PY_199  PZ_199       truthE     truthPX     truthPY      truthPZ  ttv  \\\n",
       "375     0.0     0.0     0.000000    0.000000    0.000000     0.000000    0   \n",
       "377     0.0     0.0     0.000000    0.000000    0.000000     0.000000    0   \n",
       "378     0.0     0.0     0.000000    0.000000    0.000000     0.000000    0   \n",
       "379     0.0     0.0     0.000000    0.000000    0.000000     0.000000    0   \n",
       "380     0.0     0.0     0.000000    0.000000    0.000000     0.000000    0   \n",
       "..      ...     ...          ...         ...         ...          ...  ...   \n",
       "587     0.0     0.0  1301.364624   48.551048  674.270081 -1098.891968    0   \n",
       "591     0.0     0.0  1550.415405  -38.385075 -626.145813  1406.682983    0   \n",
       "592     0.0     0.0   654.942383  394.933441  467.778076  -162.717285    0   \n",
       "593     0.0     0.0  1100.826904  220.153702 -566.737549   901.328003    0   \n",
       "596     0.0     0.0  1407.074341 -177.511642 -737.924438 -1172.384033    0   \n",
       "\n",
       "     is_signal_new  \n",
       "375              0  \n",
       "377              0  \n",
       "378              0  \n",
       "379              0  \n",
       "380              0  \n",
       "..             ...  \n",
       "587              1  \n",
       "591              1  \n",
       "592              1  \n",
       "593              1  \n",
       "596              1  \n",
       "\n",
       "[1211000 rows x 806 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 1211000 rows x 806 columns. 1211000 means there are 1.2 million jets, 806 columns means we have E0,PX0,PY0,PZ0 to E199.PX199,PY199,PZ199(800) with  truthE,truthPX,truthPY,truthPZ,ttv,and is_signal_new.\n",
    "\n",
    "This means for each jet, we are at most 200 momenta, 1 truth momenta and we can check what kind of dataset by ttv, and wheather it is a signal(top ) or a background(qcd) by is_signal_new(1 for signal 0 for background)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input for LOLA is four momenta array, we need to process them to a four momenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605477, 806)\n",
      "(605523, 806)\n"
     ]
    }
   ],
   "source": [
    "#first we will split the train dataset from signal and background.\n",
    "signal = store[store['is_signal_new']==1]\n",
    "background = store[store['is_signal_new']==0]\n",
    "print(signal.shape)\n",
    "print(background.shape)\n",
    "#we can see there are 600k of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmomenta(dataset, nConstituents=40):\n",
    "    #this function takes a input of top tagging dataset and return a four momenta array\n",
    "    momenta = dataset.values[:, :nConstituents*4]\n",
    "    momenta = np.reshape(momenta, (len(momenta), nConstituents, 4))\n",
    "    momenta = np.transpose(momenta, [0, 2, 1])\n",
    "    labels = dataset.values[:, -1]\n",
    "    labels = keras.utils.to_categorical(labels, 2)\n",
    "    indices = np.random.permutation(len(labels))\n",
    "    return momenta[indices],labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_momenta,signal_labels=loadmomenta(signal)\n",
    "background_momenta,background_labels=loadmomenta(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "momenta = np.append(background_momenta, signal_momenta, axis=0)\n",
    "labels = keras.utils.to_categorical(np.append(background_label, signal_labels), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cola class and Lola class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "  \n",
    "from keras.layers import *\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import keras, time\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CoLa():\n",
    "    \"\"\"Combination layer that returns the input and appends some linear \n",
    "    combinations along the last dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, nAdded, **kwargs):\n",
    "        # Set the number of added combinations\n",
    "        self.nAdded = nAdded\n",
    "        super(CoLa, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create trainable weight for the linear combination\n",
    "        self.combination = self.add_weight(name='combination',\n",
    "                    shape=(input_shape[2], self.nAdded),\n",
    "                    initializer='uniform',\n",
    "                    trainable=True)\n",
    "        super(CoLa, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Generate combinations and return input with appended with combinations\n",
    "        combined = K.dot(x, self.combination)\n",
    "        return K.concatenate([x, combined], axis=2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        self.out_shape = (input_shape[0], \n",
    "                    input_shape[1], \n",
    "                    input_shape[2] + self.nAdded)\n",
    "        return self.out_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        # Store nAdded value for loading saved models later\n",
    "        base_config = super(CoLa, self).get_config()\n",
    "        base_config['nAdded'] = self.nAdded\n",
    "        return base_config\n",
    "\n",
    "\n",
    "class LoLa():\n",
    "    \"\"\"Lorentz Layer adapted from arXiv:1707.08966\n",
    "    From an input of 4 vectors generate some physical quantities that serve as\n",
    "    input to a classifiction network\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LoLa, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer = keras.initializers.TruncatedNormal(mean=0., stddev=0.1)\n",
    "        metric = keras.initializers.Constant(value=[[1., -1., -1., -1.]])\n",
    "        # Trainable metric for 4-vector multiplication\n",
    "        self.metric = self.add_weight(name='metric',\n",
    "                    shape=(1, 4),\n",
    "                    initializer=metric,\n",
    "                    trainable=True)\n",
    "\n",
    "        # Weights for the linear combination of energies\n",
    "        self.energyCombination = self.add_weight(name='energyCombination',\n",
    "                    shape=(input_shape[-1], input_shape[-1]),\n",
    "                    initializer=initializer,\n",
    "                    trainable=True)\n",
    "        \n",
    "        # Weights for the linear combinations of distances\n",
    "        self.distanceCombination = self.add_weight(name='distanceCombination',\n",
    "                    shape=(input_shape[2], 4),\n",
    "                    initializer=initializer,\n",
    "                    trainable=True)\n",
    "        super(LoLa, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        def getDistanceMatrix(x):\n",
    "            \"\"\"Input:\n",
    "            x, (batchsize, features, nConst) - array of vectors\n",
    "            Returns:\n",
    "            dists, (batchsize, nConst, nConst) - distance array for every jet\n",
    "            \"\"\"\n",
    "            part1 = -2 * K.batch_dot(x, K.permute_dimensions(x, (0, 2, 1)))\n",
    "            part2 = K.permute_dimensions(K.expand_dims(K.sum(x**2, axis=2)), (0, 2, 1))\n",
    "            part3 = K.expand_dims(K.sum(x**2, axis=2))\n",
    "            dists = part1 + part2 + part3\n",
    "            return dists\n",
    "\n",
    "        # Get mass of each 4-momentum\n",
    "        mass = K.dot(self.metric, K.square(x))\n",
    "        mass = K.permute_dimensions(mass, (1, 0, 2))\n",
    "\n",
    "        # Get pT of each 4-momentum\n",
    "        pT = x[:, 1, :] ** 2 + x[:, 2, :] ** 2\n",
    "        pT = K.sqrt(K.reshape(pT, (K.shape(pT)[0], 1, K.shape(pT)[1])))\n",
    "        \n",
    "        # Get a learnable linear combination of the energies of all constituents\n",
    "        energies = K.dot(x[:, 0, :], self.energyCombination)\n",
    "        energies = K.reshape(energies, \n",
    "                            (K.shape(energies)[0], 1, K.shape(energies)[1]))\n",
    " \n",
    "        # Get the distance matrix and do some linear combination\n",
    "        dists_3 = getDistanceMatrix(\n",
    "                            K.permute_dimensions(x[:, 1:, :], (0, 2, 1)))\n",
    "        dists_0 = getDistanceMatrix(\n",
    "                            K.permute_dimensions(x[:, 0, None, :], (0, 2, 1)))\n",
    "        dists = dists_0 - dists_3\n",
    "        \n",
    "        dists = K.dot(dists, self.distanceCombination)\n",
    "        dists = K.permute_dimensions(dists, (0, 2, 1))\n",
    "\n",
    "        return K.concatenate([mass, pT, energies, dists], axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 7, input_shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LoLaClassifier(layers):\n",
    "    def __init__(self, nConstituents, nAdded, tag=0):\n",
    "        self.tag = tag\n",
    "        self.model = self._genNetwork(nConstituents, nAdded)\n",
    "        pass\n",
    "\n",
    "    def _genNetwork(self, nConstituents, nAdded):\n",
    "        input = Input((4, nConstituents))\n",
    "        layer = input\n",
    "\n",
    "        # Combination layer adds nAdded linear combinations of vectors\n",
    "        layer = CoLa(nAdded=nAdded, name='cola')(layer)\n",
    "        print (layer.value)\n",
    "        # LoLa replaces the 4 vectors by physically more meaningful vectors\n",
    "        layer = LoLa(name='lola')(layer) \n",
    "        print (layer)\n",
    "\n",
    "        # Connect to a fully connected network for classification\n",
    "        layer = Flatten()(layer)\n",
    "        layer = Dense(100, activation='relu')(layer)\n",
    "        #layer = Dense(50, activation='relu')(layer)\n",
    "        layer = Dense(10, activation='relu')(layer)\n",
    "        layer = Dense(2, activation='softmax')(layer)\n",
    "        \n",
    "        model = keras.Model(input, layer)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise:Try to run the model and train the dataset we created and make a roc curve to see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
